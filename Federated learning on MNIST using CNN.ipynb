{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "contemporary-grain",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import syft as sy\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "golden-wagon",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_raw = pd.read_csv('MNIST/mnist_train.csv')\n",
    "inputs = dataframe_raw.drop('label',axis=1).values/255\n",
    "targets = dataframe_raw[['label']].values\n",
    "inputs = inputs.reshape(-1,1,28,28)\n",
    "dataset_train = TensorDataset(torch.tensor(inputs,dtype=torch.float32),torch.tensor(targets,dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sized-penetration",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_raw = pd.read_csv('MNIST/mnist_test.csv')\n",
    "inputs = dataframe_raw.drop('label',axis=1).values/255\n",
    "targets = dataframe_raw[['label']].values\n",
    "inputs = inputs.reshape(-1,1,28,28)\n",
    "dataset_test = TensorDataset(torch.tensor(inputs,dtype=torch.float32),torch.tensor(targets,dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "medium-greensboro",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook = sy.TorchHook(torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "boxed-detroit",
   "metadata": {},
   "outputs": [],
   "source": [
    "jake = sy.VirtualWorker(hook, id=\"jake\")\n",
    "john = sy.VirtualWorker(hook, id=\"john\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "vital-crack",
   "metadata": {},
   "outputs": [],
   "source": [
    "federated_train_loader = sy.FederatedDataLoader(\n",
    "    dataset_train.federate((jake, john)), batch_size=64, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset_test, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "elegant-frederick",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch(dl):\n",
    "    for images, labels in dl:\n",
    "        print(images.size())\n",
    "        print(labels.size())\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "later-market",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 1])\n"
     ]
    }
   ],
   "source": [
    "show_batch(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "occupied-stereo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the args\n",
    "args = {\n",
    "    'use_cuda' : True,\n",
    "    'batch_size' : 64,\n",
    "    'test_batch_size' : 1000,\n",
    "    'lr' : 0.01,\n",
    "    'log_interval' : 10,\n",
    "    'epochs' : 10\n",
    "}\n",
    "use_cuda = args['use_cuda'] and torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "southeast-duncan",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 1, out_channels = 32, kernel_size = 3, stride = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=32,out_channels = 64, kernel_size = 3, stride = 1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_features=64*12*12, out_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=128, out_features=10),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = F.max_pool2d(x,2)\n",
    "        x = x.view(-1, 64*12*12)\n",
    "        x = self.fc(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "successful-deposit",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    # iterate over federated data\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # send the model to the remote location \n",
    "        model = model.send(data.location)\n",
    "        \n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "\n",
    "        # this loss is a ptr to the tensor loss at the remote location\n",
    "        loss = F.nll_loss(output, target.view(-1).long())\n",
    "\n",
    "        # call backward() on the loss ptr,that will send the command to call\n",
    "        # backward on the actual loss tensor present on the remote machine\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # get back the updated model\n",
    "        model.get()\n",
    "\n",
    "        if batch_idx % args['log_interval'] == 0:\n",
    "\n",
    "            # a thing to note is the variable loss was also created at remote worker, so we need to explicitly get it back\n",
    "            loss = loss.get()\n",
    "\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, \n",
    "                    batch_idx * args['batch_size'], # no of images done\n",
    "                    len(train_loader) * args['batch_size'], # total images left\n",
    "                    100. * batch_idx / len(train_loader), \n",
    "                    loss.item()\n",
    "                )\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "statewide-processor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "\n",
    "            # add losses together\n",
    "            test_loss += F.nll_loss(output, target.view(-1).long(), reduction='sum').item() \n",
    "            pred = output.argmax(dim=1, keepdim=True)  \n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "confirmed-scene",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60032 (0%)]\tLoss: 2.300661\n",
      "Train Epoch: 1 [640/60032 (1%)]\tLoss: 2.300676\n",
      "Train Epoch: 1 [1280/60032 (2%)]\tLoss: 2.269510\n",
      "Train Epoch: 1 [1920/60032 (3%)]\tLoss: 2.266171\n",
      "Train Epoch: 1 [2560/60032 (4%)]\tLoss: 2.258022\n",
      "Train Epoch: 1 [3200/60032 (5%)]\tLoss: 2.253899\n",
      "Train Epoch: 1 [3840/60032 (6%)]\tLoss: 2.246850\n",
      "Train Epoch: 1 [4480/60032 (7%)]\tLoss: 2.209277\n",
      "Train Epoch: 1 [5120/60032 (9%)]\tLoss: 2.201339\n",
      "Train Epoch: 1 [5760/60032 (10%)]\tLoss: 2.171238\n",
      "Train Epoch: 1 [6400/60032 (11%)]\tLoss: 2.132794\n",
      "Train Epoch: 1 [7040/60032 (12%)]\tLoss: 2.083695\n",
      "Train Epoch: 1 [7680/60032 (13%)]\tLoss: 1.975187\n",
      "Train Epoch: 1 [8320/60032 (14%)]\tLoss: 1.946896\n",
      "Train Epoch: 1 [8960/60032 (15%)]\tLoss: 1.850954\n",
      "Train Epoch: 1 [9600/60032 (16%)]\tLoss: 1.741868\n",
      "Train Epoch: 1 [10240/60032 (17%)]\tLoss: 1.501534\n",
      "Train Epoch: 1 [10880/60032 (18%)]\tLoss: 1.401706\n",
      "Train Epoch: 1 [11520/60032 (19%)]\tLoss: 1.186644\n",
      "Train Epoch: 1 [12160/60032 (20%)]\tLoss: 0.941222\n",
      "Train Epoch: 1 [12800/60032 (21%)]\tLoss: 1.063354\n",
      "Train Epoch: 1 [13440/60032 (22%)]\tLoss: 0.849161\n",
      "Train Epoch: 1 [14080/60032 (23%)]\tLoss: 0.833217\n",
      "Train Epoch: 1 [14720/60032 (25%)]\tLoss: 0.583755\n",
      "Train Epoch: 1 [15360/60032 (26%)]\tLoss: 0.651837\n",
      "Train Epoch: 1 [16000/60032 (27%)]\tLoss: 0.496122\n",
      "Train Epoch: 1 [16640/60032 (28%)]\tLoss: 0.581749\n",
      "Train Epoch: 1 [17280/60032 (29%)]\tLoss: 0.673953\n",
      "Train Epoch: 1 [17920/60032 (30%)]\tLoss: 0.506274\n",
      "Train Epoch: 1 [18560/60032 (31%)]\tLoss: 0.754534\n",
      "Train Epoch: 1 [19200/60032 (32%)]\tLoss: 0.383883\n",
      "Train Epoch: 1 [19840/60032 (33%)]\tLoss: 0.349926\n",
      "Train Epoch: 1 [20480/60032 (34%)]\tLoss: 0.319914\n",
      "Train Epoch: 1 [21120/60032 (35%)]\tLoss: 0.433377\n",
      "Train Epoch: 1 [21760/60032 (36%)]\tLoss: 0.452411\n",
      "Train Epoch: 1 [22400/60032 (37%)]\tLoss: 0.438299\n",
      "Train Epoch: 1 [23040/60032 (38%)]\tLoss: 0.330338\n",
      "Train Epoch: 1 [23680/60032 (39%)]\tLoss: 0.543509\n",
      "Train Epoch: 1 [24320/60032 (41%)]\tLoss: 0.505456\n",
      "Train Epoch: 1 [24960/60032 (42%)]\tLoss: 0.389973\n",
      "Train Epoch: 1 [25600/60032 (43%)]\tLoss: 0.291635\n",
      "Train Epoch: 1 [26240/60032 (44%)]\tLoss: 0.222943\n",
      "Train Epoch: 1 [26880/60032 (45%)]\tLoss: 0.412902\n",
      "Train Epoch: 1 [27520/60032 (46%)]\tLoss: 0.312916\n",
      "Train Epoch: 1 [28160/60032 (47%)]\tLoss: 0.417519\n",
      "Train Epoch: 1 [28800/60032 (48%)]\tLoss: 0.253922\n",
      "Train Epoch: 1 [29440/60032 (49%)]\tLoss: 0.241234\n",
      "Train Epoch: 1 [30080/60032 (50%)]\tLoss: 0.461915\n",
      "Train Epoch: 1 [30720/60032 (51%)]\tLoss: 0.372974\n",
      "Train Epoch: 1 [31360/60032 (52%)]\tLoss: 0.353758\n",
      "Train Epoch: 1 [32000/60032 (53%)]\tLoss: 0.398274\n",
      "Train Epoch: 1 [32640/60032 (54%)]\tLoss: 0.362011\n",
      "Train Epoch: 1 [33280/60032 (55%)]\tLoss: 0.409618\n",
      "Train Epoch: 1 [33920/60032 (57%)]\tLoss: 0.472651\n",
      "Train Epoch: 1 [34560/60032 (58%)]\tLoss: 0.298800\n",
      "Train Epoch: 1 [35200/60032 (59%)]\tLoss: 0.446924\n",
      "Train Epoch: 1 [35840/60032 (60%)]\tLoss: 0.280010\n",
      "Train Epoch: 1 [36480/60032 (61%)]\tLoss: 0.466105\n",
      "Train Epoch: 1 [37120/60032 (62%)]\tLoss: 0.532140\n",
      "Train Epoch: 1 [37760/60032 (63%)]\tLoss: 0.184283\n",
      "Train Epoch: 1 [38400/60032 (64%)]\tLoss: 0.371580\n",
      "Train Epoch: 1 [39040/60032 (65%)]\tLoss: 0.371363\n",
      "Train Epoch: 1 [39680/60032 (66%)]\tLoss: 0.199742\n",
      "Train Epoch: 1 [40320/60032 (67%)]\tLoss: 0.482659\n",
      "Train Epoch: 1 [40960/60032 (68%)]\tLoss: 0.367397\n",
      "Train Epoch: 1 [41600/60032 (69%)]\tLoss: 0.237651\n",
      "Train Epoch: 1 [42240/60032 (70%)]\tLoss: 0.453838\n",
      "Train Epoch: 1 [42880/60032 (71%)]\tLoss: 0.219225\n",
      "Train Epoch: 1 [43520/60032 (72%)]\tLoss: 0.182518\n",
      "Train Epoch: 1 [44160/60032 (74%)]\tLoss: 0.291091\n",
      "Train Epoch: 1 [44800/60032 (75%)]\tLoss: 0.404483\n",
      "Train Epoch: 1 [45440/60032 (76%)]\tLoss: 0.381530\n",
      "Train Epoch: 1 [46080/60032 (77%)]\tLoss: 0.250869\n",
      "Train Epoch: 1 [46720/60032 (78%)]\tLoss: 0.216017\n",
      "Train Epoch: 1 [47360/60032 (79%)]\tLoss: 0.432037\n",
      "Train Epoch: 1 [48000/60032 (80%)]\tLoss: 0.268842\n",
      "Train Epoch: 1 [48640/60032 (81%)]\tLoss: 0.324107\n",
      "Train Epoch: 1 [49280/60032 (82%)]\tLoss: 0.181300\n",
      "Train Epoch: 1 [49920/60032 (83%)]\tLoss: 0.211652\n",
      "Train Epoch: 1 [50560/60032 (84%)]\tLoss: 0.279176\n",
      "Train Epoch: 1 [51200/60032 (85%)]\tLoss: 0.297042\n",
      "Train Epoch: 1 [51840/60032 (86%)]\tLoss: 0.313557\n",
      "Train Epoch: 1 [52480/60032 (87%)]\tLoss: 0.226262\n",
      "Train Epoch: 1 [53120/60032 (88%)]\tLoss: 0.210040\n",
      "Train Epoch: 1 [53760/60032 (90%)]\tLoss: 0.567585\n",
      "Train Epoch: 1 [54400/60032 (91%)]\tLoss: 0.202615\n",
      "Train Epoch: 1 [55040/60032 (92%)]\tLoss: 0.348148\n",
      "Train Epoch: 1 [55680/60032 (93%)]\tLoss: 0.394497\n",
      "Train Epoch: 1 [56320/60032 (94%)]\tLoss: 0.254925\n",
      "Train Epoch: 1 [56960/60032 (95%)]\tLoss: 0.186150\n",
      "Train Epoch: 1 [57600/60032 (96%)]\tLoss: 0.196320\n",
      "Train Epoch: 1 [58240/60032 (97%)]\tLoss: 0.351525\n",
      "Train Epoch: 1 [58880/60032 (98%)]\tLoss: 0.288620\n",
      "Train Epoch: 1 [59520/60032 (99%)]\tLoss: 0.254595\n",
      "\n",
      "Test set: Average loss: 0.2742, Accuracy: 9167/10000 (92%)\n",
      "\n",
      "Train Epoch: 2 [0/60032 (0%)]\tLoss: 0.170445\n",
      "Train Epoch: 2 [640/60032 (1%)]\tLoss: 0.253325\n",
      "Train Epoch: 2 [1280/60032 (2%)]\tLoss: 0.156448\n",
      "Train Epoch: 2 [1920/60032 (3%)]\tLoss: 0.156026\n",
      "Train Epoch: 2 [2560/60032 (4%)]\tLoss: 0.190293\n",
      "Train Epoch: 2 [3200/60032 (5%)]\tLoss: 0.234587\n",
      "Train Epoch: 2 [3840/60032 (6%)]\tLoss: 0.452783\n",
      "Train Epoch: 2 [4480/60032 (7%)]\tLoss: 0.412504\n",
      "Train Epoch: 2 [5120/60032 (9%)]\tLoss: 0.180052\n",
      "Train Epoch: 2 [5760/60032 (10%)]\tLoss: 0.143707\n",
      "Train Epoch: 2 [6400/60032 (11%)]\tLoss: 0.152454\n",
      "Train Epoch: 2 [7040/60032 (12%)]\tLoss: 0.202364\n",
      "Train Epoch: 2 [7680/60032 (13%)]\tLoss: 0.291288\n",
      "Train Epoch: 2 [8320/60032 (14%)]\tLoss: 0.150037\n",
      "Train Epoch: 2 [8960/60032 (15%)]\tLoss: 0.167029\n",
      "Train Epoch: 2 [9600/60032 (16%)]\tLoss: 0.272406\n",
      "Train Epoch: 2 [10240/60032 (17%)]\tLoss: 0.321280\n",
      "Train Epoch: 2 [10880/60032 (18%)]\tLoss: 0.262155\n",
      "Train Epoch: 2 [11520/60032 (19%)]\tLoss: 0.452679\n",
      "Train Epoch: 2 [12160/60032 (20%)]\tLoss: 0.179920\n",
      "Train Epoch: 2 [12800/60032 (21%)]\tLoss: 0.374495\n",
      "Train Epoch: 2 [13440/60032 (22%)]\tLoss: 0.096682\n",
      "Train Epoch: 2 [14080/60032 (23%)]\tLoss: 0.315018\n",
      "Train Epoch: 2 [14720/60032 (25%)]\tLoss: 0.157700\n",
      "Train Epoch: 2 [15360/60032 (26%)]\tLoss: 0.354295\n",
      "Train Epoch: 2 [16000/60032 (27%)]\tLoss: 0.239091\n",
      "Train Epoch: 2 [16640/60032 (28%)]\tLoss: 0.401166\n",
      "Train Epoch: 2 [17280/60032 (29%)]\tLoss: 0.354612\n",
      "Train Epoch: 2 [17920/60032 (30%)]\tLoss: 0.307666\n",
      "Train Epoch: 2 [18560/60032 (31%)]\tLoss: 0.396040\n",
      "Train Epoch: 2 [19200/60032 (32%)]\tLoss: 0.149191\n",
      "Train Epoch: 2 [19840/60032 (33%)]\tLoss: 0.324699\n",
      "Train Epoch: 2 [20480/60032 (34%)]\tLoss: 0.149592\n",
      "Train Epoch: 2 [21120/60032 (35%)]\tLoss: 0.117626\n",
      "Train Epoch: 2 [21760/60032 (36%)]\tLoss: 0.179575\n",
      "Train Epoch: 2 [22400/60032 (37%)]\tLoss: 0.239167\n",
      "Train Epoch: 2 [23040/60032 (38%)]\tLoss: 0.255253\n",
      "Train Epoch: 2 [23680/60032 (39%)]\tLoss: 0.166143\n",
      "Train Epoch: 2 [24320/60032 (41%)]\tLoss: 0.130719\n",
      "Train Epoch: 2 [24960/60032 (42%)]\tLoss: 0.275525\n",
      "Train Epoch: 2 [25600/60032 (43%)]\tLoss: 0.214053\n",
      "Train Epoch: 2 [26240/60032 (44%)]\tLoss: 0.474093\n",
      "Train Epoch: 2 [26880/60032 (45%)]\tLoss: 0.330184\n",
      "Train Epoch: 2 [27520/60032 (46%)]\tLoss: 0.132000\n",
      "Train Epoch: 2 [28160/60032 (47%)]\tLoss: 0.171522\n",
      "Train Epoch: 2 [28800/60032 (48%)]\tLoss: 0.212016\n",
      "Train Epoch: 2 [29440/60032 (49%)]\tLoss: 0.133396\n",
      "Train Epoch: 2 [30080/60032 (50%)]\tLoss: 0.340661\n",
      "Train Epoch: 2 [30720/60032 (51%)]\tLoss: 0.122160\n",
      "Train Epoch: 2 [31360/60032 (52%)]\tLoss: 0.280580\n",
      "Train Epoch: 2 [32000/60032 (53%)]\tLoss: 0.219760\n",
      "Train Epoch: 2 [32640/60032 (54%)]\tLoss: 0.156804\n",
      "Train Epoch: 2 [33280/60032 (55%)]\tLoss: 0.307512\n",
      "Train Epoch: 2 [33920/60032 (57%)]\tLoss: 0.216444\n",
      "Train Epoch: 2 [34560/60032 (58%)]\tLoss: 0.171102\n",
      "Train Epoch: 2 [35200/60032 (59%)]\tLoss: 0.137722\n",
      "Train Epoch: 2 [35840/60032 (60%)]\tLoss: 0.446383\n",
      "Train Epoch: 2 [36480/60032 (61%)]\tLoss: 0.084818\n",
      "Train Epoch: 2 [37120/60032 (62%)]\tLoss: 0.070541\n",
      "Train Epoch: 2 [37760/60032 (63%)]\tLoss: 0.138315\n",
      "Train Epoch: 2 [38400/60032 (64%)]\tLoss: 0.180929\n",
      "Train Epoch: 2 [39040/60032 (65%)]\tLoss: 0.119431\n",
      "Train Epoch: 2 [39680/60032 (66%)]\tLoss: 0.103683\n",
      "Train Epoch: 2 [40320/60032 (67%)]\tLoss: 0.106493\n",
      "Train Epoch: 2 [40960/60032 (68%)]\tLoss: 0.235532\n",
      "Train Epoch: 2 [41600/60032 (69%)]\tLoss: 0.301834\n",
      "Train Epoch: 2 [42240/60032 (70%)]\tLoss: 0.153400\n",
      "Train Epoch: 2 [42880/60032 (71%)]\tLoss: 0.216464\n",
      "Train Epoch: 2 [43520/60032 (72%)]\tLoss: 0.202565\n",
      "Train Epoch: 2 [44160/60032 (74%)]\tLoss: 0.349604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [44800/60032 (75%)]\tLoss: 0.203324\n",
      "Train Epoch: 2 [45440/60032 (76%)]\tLoss: 0.116181\n",
      "Train Epoch: 2 [46080/60032 (77%)]\tLoss: 0.290682\n",
      "Train Epoch: 2 [46720/60032 (78%)]\tLoss: 0.263639\n",
      "Train Epoch: 2 [47360/60032 (79%)]\tLoss: 0.070138\n",
      "Train Epoch: 2 [48000/60032 (80%)]\tLoss: 0.238364\n",
      "Train Epoch: 2 [48640/60032 (81%)]\tLoss: 0.224333\n",
      "Train Epoch: 2 [49280/60032 (82%)]\tLoss: 0.122876\n",
      "Train Epoch: 2 [49920/60032 (83%)]\tLoss: 0.117534\n",
      "Train Epoch: 2 [50560/60032 (84%)]\tLoss: 0.146825\n",
      "Train Epoch: 2 [51200/60032 (85%)]\tLoss: 0.241283\n",
      "Train Epoch: 2 [51840/60032 (86%)]\tLoss: 0.075421\n",
      "Train Epoch: 2 [52480/60032 (87%)]\tLoss: 0.108849\n",
      "Train Epoch: 2 [53120/60032 (88%)]\tLoss: 0.206410\n",
      "Train Epoch: 2 [53760/60032 (90%)]\tLoss: 0.244172\n",
      "Train Epoch: 2 [54400/60032 (91%)]\tLoss: 0.075590\n",
      "Train Epoch: 2 [55040/60032 (92%)]\tLoss: 0.394088\n",
      "Train Epoch: 2 [55680/60032 (93%)]\tLoss: 0.105463\n",
      "Train Epoch: 2 [56320/60032 (94%)]\tLoss: 0.237759\n",
      "Train Epoch: 2 [56960/60032 (95%)]\tLoss: 0.202400\n",
      "Train Epoch: 2 [57600/60032 (96%)]\tLoss: 0.263797\n",
      "Train Epoch: 2 [58240/60032 (97%)]\tLoss: 0.222609\n",
      "Train Epoch: 2 [58880/60032 (98%)]\tLoss: 0.200464\n",
      "Train Epoch: 2 [59520/60032 (99%)]\tLoss: 0.142707\n",
      "\n",
      "Test set: Average loss: 0.1767, Accuracy: 9460/10000 (95%)\n",
      "\n",
      "Train Epoch: 3 [0/60032 (0%)]\tLoss: 0.102640\n",
      "Train Epoch: 3 [640/60032 (1%)]\tLoss: 0.121627\n",
      "Train Epoch: 3 [1280/60032 (2%)]\tLoss: 0.104491\n",
      "Train Epoch: 3 [1920/60032 (3%)]\tLoss: 0.114958\n",
      "Train Epoch: 3 [2560/60032 (4%)]\tLoss: 0.176340\n",
      "Train Epoch: 3 [3200/60032 (5%)]\tLoss: 0.279618\n",
      "Train Epoch: 3 [3840/60032 (6%)]\tLoss: 0.193856\n",
      "Train Epoch: 3 [4480/60032 (7%)]\tLoss: 0.291402\n",
      "Train Epoch: 3 [5120/60032 (9%)]\tLoss: 0.060161\n",
      "Train Epoch: 3 [5760/60032 (10%)]\tLoss: 0.222700\n",
      "Train Epoch: 3 [6400/60032 (11%)]\tLoss: 0.390852\n",
      "Train Epoch: 3 [7040/60032 (12%)]\tLoss: 0.225863\n",
      "Train Epoch: 3 [7680/60032 (13%)]\tLoss: 0.197643\n",
      "Train Epoch: 3 [8320/60032 (14%)]\tLoss: 0.086780\n",
      "Train Epoch: 3 [8960/60032 (15%)]\tLoss: 0.091643\n",
      "Train Epoch: 3 [9600/60032 (16%)]\tLoss: 0.139565\n",
      "Train Epoch: 3 [10240/60032 (17%)]\tLoss: 0.232999\n",
      "Train Epoch: 3 [10880/60032 (18%)]\tLoss: 0.249415\n",
      "Train Epoch: 3 [11520/60032 (19%)]\tLoss: 0.129353\n",
      "Train Epoch: 3 [12160/60032 (20%)]\tLoss: 0.146551\n",
      "Train Epoch: 3 [12800/60032 (21%)]\tLoss: 0.234042\n",
      "Train Epoch: 3 [13440/60032 (22%)]\tLoss: 0.176226\n",
      "Train Epoch: 3 [14080/60032 (23%)]\tLoss: 0.156807\n",
      "Train Epoch: 3 [14720/60032 (25%)]\tLoss: 0.246325\n",
      "Train Epoch: 3 [15360/60032 (26%)]\tLoss: 0.218986\n",
      "Train Epoch: 3 [16000/60032 (27%)]\tLoss: 0.247578\n",
      "Train Epoch: 3 [16640/60032 (28%)]\tLoss: 0.185470\n",
      "Train Epoch: 3 [17280/60032 (29%)]\tLoss: 0.210302\n",
      "Train Epoch: 3 [17920/60032 (30%)]\tLoss: 0.296097\n",
      "Train Epoch: 3 [18560/60032 (31%)]\tLoss: 0.243250\n",
      "Train Epoch: 3 [19200/60032 (32%)]\tLoss: 0.140299\n",
      "Train Epoch: 3 [19840/60032 (33%)]\tLoss: 0.061836\n",
      "Train Epoch: 3 [20480/60032 (34%)]\tLoss: 0.106957\n",
      "Train Epoch: 3 [21120/60032 (35%)]\tLoss: 0.201825\n",
      "Train Epoch: 3 [21760/60032 (36%)]\tLoss: 0.171317\n",
      "Train Epoch: 3 [22400/60032 (37%)]\tLoss: 0.287567\n",
      "Train Epoch: 3 [23040/60032 (38%)]\tLoss: 0.134893\n",
      "Train Epoch: 3 [23680/60032 (39%)]\tLoss: 0.050126\n",
      "Train Epoch: 3 [24320/60032 (41%)]\tLoss: 0.106859\n",
      "Train Epoch: 3 [24960/60032 (42%)]\tLoss: 0.187981\n",
      "Train Epoch: 3 [25600/60032 (43%)]\tLoss: 0.152175\n",
      "Train Epoch: 3 [26240/60032 (44%)]\tLoss: 0.117025\n",
      "Train Epoch: 3 [26880/60032 (45%)]\tLoss: 0.304803\n",
      "Train Epoch: 3 [27520/60032 (46%)]\tLoss: 0.119362\n",
      "Train Epoch: 3 [28160/60032 (47%)]\tLoss: 0.311586\n",
      "Train Epoch: 3 [28800/60032 (48%)]\tLoss: 0.157659\n",
      "Train Epoch: 3 [29440/60032 (49%)]\tLoss: 0.033106\n",
      "Train Epoch: 3 [30080/60032 (50%)]\tLoss: 0.163735\n",
      "Train Epoch: 3 [30720/60032 (51%)]\tLoss: 0.062838\n",
      "Train Epoch: 3 [31360/60032 (52%)]\tLoss: 0.149530\n",
      "Train Epoch: 3 [32000/60032 (53%)]\tLoss: 0.332589\n",
      "Train Epoch: 3 [32640/60032 (54%)]\tLoss: 0.154952\n",
      "Train Epoch: 3 [33280/60032 (55%)]\tLoss: 0.179911\n",
      "Train Epoch: 3 [33920/60032 (57%)]\tLoss: 0.110901\n",
      "Train Epoch: 3 [34560/60032 (58%)]\tLoss: 0.132932\n",
      "Train Epoch: 3 [35200/60032 (59%)]\tLoss: 0.204914\n",
      "Train Epoch: 3 [35840/60032 (60%)]\tLoss: 0.236714\n",
      "Train Epoch: 3 [36480/60032 (61%)]\tLoss: 0.150046\n",
      "Train Epoch: 3 [37120/60032 (62%)]\tLoss: 0.117381\n",
      "Train Epoch: 3 [37760/60032 (63%)]\tLoss: 0.138443\n",
      "Train Epoch: 3 [38400/60032 (64%)]\tLoss: 0.265243\n",
      "Train Epoch: 3 [39040/60032 (65%)]\tLoss: 0.190962\n",
      "Train Epoch: 3 [39680/60032 (66%)]\tLoss: 0.248998\n",
      "Train Epoch: 3 [40320/60032 (67%)]\tLoss: 0.114799\n",
      "Train Epoch: 3 [40960/60032 (68%)]\tLoss: 0.163924\n",
      "Train Epoch: 3 [41600/60032 (69%)]\tLoss: 0.113320\n",
      "Train Epoch: 3 [42240/60032 (70%)]\tLoss: 0.286160\n",
      "Train Epoch: 3 [42880/60032 (71%)]\tLoss: 0.177242\n",
      "Train Epoch: 3 [43520/60032 (72%)]\tLoss: 0.152309\n",
      "Train Epoch: 3 [44160/60032 (74%)]\tLoss: 0.093748\n",
      "Train Epoch: 3 [44800/60032 (75%)]\tLoss: 0.067813\n",
      "Train Epoch: 3 [45440/60032 (76%)]\tLoss: 0.162502\n",
      "Train Epoch: 3 [46080/60032 (77%)]\tLoss: 0.252375\n",
      "Train Epoch: 3 [46720/60032 (78%)]\tLoss: 0.125467\n",
      "Train Epoch: 3 [47360/60032 (79%)]\tLoss: 0.161084\n",
      "Train Epoch: 3 [48000/60032 (80%)]\tLoss: 0.081780\n",
      "Train Epoch: 3 [48640/60032 (81%)]\tLoss: 0.236075\n",
      "Train Epoch: 3 [49280/60032 (82%)]\tLoss: 0.231167\n",
      "Train Epoch: 3 [49920/60032 (83%)]\tLoss: 0.143929\n",
      "Train Epoch: 3 [50560/60032 (84%)]\tLoss: 0.230930\n",
      "Train Epoch: 3 [51200/60032 (85%)]\tLoss: 0.211298\n",
      "Train Epoch: 3 [51840/60032 (86%)]\tLoss: 0.185597\n",
      "Train Epoch: 3 [52480/60032 (87%)]\tLoss: 0.068212\n",
      "Train Epoch: 3 [53120/60032 (88%)]\tLoss: 0.098239\n",
      "Train Epoch: 3 [53760/60032 (90%)]\tLoss: 0.167475\n",
      "Train Epoch: 3 [54400/60032 (91%)]\tLoss: 0.040255\n",
      "Train Epoch: 3 [55040/60032 (92%)]\tLoss: 0.115900\n",
      "Train Epoch: 3 [55680/60032 (93%)]\tLoss: 0.131835\n",
      "Train Epoch: 3 [56320/60032 (94%)]\tLoss: 0.087121\n",
      "Train Epoch: 3 [56960/60032 (95%)]\tLoss: 0.162954\n",
      "Train Epoch: 3 [57600/60032 (96%)]\tLoss: 0.171461\n",
      "Train Epoch: 3 [58240/60032 (97%)]\tLoss: 0.287071\n",
      "Train Epoch: 3 [58880/60032 (98%)]\tLoss: 0.153514\n",
      "Train Epoch: 3 [59520/60032 (99%)]\tLoss: 0.072426\n",
      "\n",
      "Test set: Average loss: 0.1568, Accuracy: 9514/10000 (95%)\n",
      "\n",
      "Train Epoch: 4 [0/60032 (0%)]\tLoss: 0.148573\n",
      "Train Epoch: 4 [640/60032 (1%)]\tLoss: 0.118783\n",
      "Train Epoch: 4 [1280/60032 (2%)]\tLoss: 0.073394\n",
      "Train Epoch: 4 [1920/60032 (3%)]\tLoss: 0.251682\n",
      "Train Epoch: 4 [2560/60032 (4%)]\tLoss: 0.320251\n",
      "Train Epoch: 4 [3200/60032 (5%)]\tLoss: 0.194668\n",
      "Train Epoch: 4 [3840/60032 (6%)]\tLoss: 0.157619\n",
      "Train Epoch: 4 [4480/60032 (7%)]\tLoss: 0.130869\n",
      "Train Epoch: 4 [5120/60032 (9%)]\tLoss: 0.183522\n",
      "Train Epoch: 4 [5760/60032 (10%)]\tLoss: 0.148824\n",
      "Train Epoch: 4 [6400/60032 (11%)]\tLoss: 0.118769\n",
      "Train Epoch: 4 [7040/60032 (12%)]\tLoss: 0.120414\n",
      "Train Epoch: 4 [7680/60032 (13%)]\tLoss: 0.204483\n",
      "Train Epoch: 4 [8320/60032 (14%)]\tLoss: 0.162779\n",
      "Train Epoch: 4 [8960/60032 (15%)]\tLoss: 0.105482\n",
      "Train Epoch: 4 [9600/60032 (16%)]\tLoss: 0.159564\n",
      "Train Epoch: 4 [10240/60032 (17%)]\tLoss: 0.172870\n",
      "Train Epoch: 4 [10880/60032 (18%)]\tLoss: 0.140574\n",
      "Train Epoch: 4 [11520/60032 (19%)]\tLoss: 0.112354\n",
      "Train Epoch: 4 [12160/60032 (20%)]\tLoss: 0.128092\n",
      "Train Epoch: 4 [12800/60032 (21%)]\tLoss: 0.136173\n",
      "Train Epoch: 4 [13440/60032 (22%)]\tLoss: 0.106824\n",
      "Train Epoch: 4 [14080/60032 (23%)]\tLoss: 0.078746\n",
      "Train Epoch: 4 [14720/60032 (25%)]\tLoss: 0.207296\n",
      "Train Epoch: 4 [15360/60032 (26%)]\tLoss: 0.080285\n",
      "Train Epoch: 4 [16000/60032 (27%)]\tLoss: 0.175513\n",
      "Train Epoch: 4 [16640/60032 (28%)]\tLoss: 0.110073\n",
      "Train Epoch: 4 [17280/60032 (29%)]\tLoss: 0.090330\n",
      "Train Epoch: 4 [17920/60032 (30%)]\tLoss: 0.062825\n",
      "Train Epoch: 4 [18560/60032 (31%)]\tLoss: 0.104589\n",
      "Train Epoch: 4 [19200/60032 (32%)]\tLoss: 0.273765\n",
      "Train Epoch: 4 [19840/60032 (33%)]\tLoss: 0.054540\n",
      "Train Epoch: 4 [20480/60032 (34%)]\tLoss: 0.281484\n",
      "Train Epoch: 4 [21120/60032 (35%)]\tLoss: 0.258641\n",
      "Train Epoch: 4 [21760/60032 (36%)]\tLoss: 0.103267\n",
      "Train Epoch: 4 [22400/60032 (37%)]\tLoss: 0.169097\n",
      "Train Epoch: 4 [23040/60032 (38%)]\tLoss: 0.271645\n",
      "Train Epoch: 4 [23680/60032 (39%)]\tLoss: 0.072852\n",
      "Train Epoch: 4 [24320/60032 (41%)]\tLoss: 0.323331\n",
      "Train Epoch: 4 [24960/60032 (42%)]\tLoss: 0.126758\n",
      "Train Epoch: 4 [25600/60032 (43%)]\tLoss: 0.195786\n",
      "Train Epoch: 4 [26240/60032 (44%)]\tLoss: 0.130937\n",
      "Train Epoch: 4 [26880/60032 (45%)]\tLoss: 0.193414\n",
      "Train Epoch: 4 [27520/60032 (46%)]\tLoss: 0.146646\n",
      "Train Epoch: 4 [28160/60032 (47%)]\tLoss: 0.173548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [28800/60032 (48%)]\tLoss: 0.128348\n",
      "Train Epoch: 4 [29440/60032 (49%)]\tLoss: 0.118972\n",
      "Train Epoch: 4 [30080/60032 (50%)]\tLoss: 0.085461\n",
      "Train Epoch: 4 [30720/60032 (51%)]\tLoss: 0.114287\n",
      "Train Epoch: 4 [31360/60032 (52%)]\tLoss: 0.141748\n",
      "Train Epoch: 4 [32000/60032 (53%)]\tLoss: 0.098521\n",
      "Train Epoch: 4 [32640/60032 (54%)]\tLoss: 0.270475\n",
      "Train Epoch: 4 [33280/60032 (55%)]\tLoss: 0.107124\n",
      "Train Epoch: 4 [33920/60032 (57%)]\tLoss: 0.100478\n",
      "Train Epoch: 4 [34560/60032 (58%)]\tLoss: 0.121096\n",
      "Train Epoch: 4 [35200/60032 (59%)]\tLoss: 0.042296\n",
      "Train Epoch: 4 [35840/60032 (60%)]\tLoss: 0.263524\n",
      "Train Epoch: 4 [36480/60032 (61%)]\tLoss: 0.274537\n",
      "Train Epoch: 4 [37120/60032 (62%)]\tLoss: 0.152648\n",
      "Train Epoch: 4 [37760/60032 (63%)]\tLoss: 0.049671\n",
      "Train Epoch: 4 [38400/60032 (64%)]\tLoss: 0.089717\n",
      "Train Epoch: 4 [39040/60032 (65%)]\tLoss: 0.287282\n",
      "Train Epoch: 4 [39680/60032 (66%)]\tLoss: 0.229501\n",
      "Train Epoch: 4 [40320/60032 (67%)]\tLoss: 0.024575\n",
      "Train Epoch: 4 [40960/60032 (68%)]\tLoss: 0.101794\n",
      "Train Epoch: 4 [41600/60032 (69%)]\tLoss: 0.300197\n",
      "Train Epoch: 4 [42240/60032 (70%)]\tLoss: 0.085416\n",
      "Train Epoch: 4 [42880/60032 (71%)]\tLoss: 0.122003\n",
      "Train Epoch: 4 [43520/60032 (72%)]\tLoss: 0.076588\n",
      "Train Epoch: 4 [44160/60032 (74%)]\tLoss: 0.056570\n",
      "Train Epoch: 4 [44800/60032 (75%)]\tLoss: 0.218575\n",
      "Train Epoch: 4 [45440/60032 (76%)]\tLoss: 0.133278\n",
      "Train Epoch: 4 [46080/60032 (77%)]\tLoss: 0.182168\n",
      "Train Epoch: 4 [46720/60032 (78%)]\tLoss: 0.126823\n",
      "Train Epoch: 4 [47360/60032 (79%)]\tLoss: 0.120328\n",
      "Train Epoch: 4 [48000/60032 (80%)]\tLoss: 0.167765\n",
      "Train Epoch: 4 [48640/60032 (81%)]\tLoss: 0.110844\n",
      "Train Epoch: 4 [49280/60032 (82%)]\tLoss: 0.034326\n",
      "Train Epoch: 4 [49920/60032 (83%)]\tLoss: 0.132043\n",
      "Train Epoch: 4 [50560/60032 (84%)]\tLoss: 0.123748\n",
      "Train Epoch: 4 [51200/60032 (85%)]\tLoss: 0.059684\n",
      "Train Epoch: 4 [51840/60032 (86%)]\tLoss: 0.129540\n",
      "Train Epoch: 4 [52480/60032 (87%)]\tLoss: 0.161339\n",
      "Train Epoch: 4 [53120/60032 (88%)]\tLoss: 0.126873\n",
      "Train Epoch: 4 [53760/60032 (90%)]\tLoss: 0.054423\n",
      "Train Epoch: 4 [54400/60032 (91%)]\tLoss: 0.113002\n",
      "Train Epoch: 4 [55040/60032 (92%)]\tLoss: 0.030722\n",
      "Train Epoch: 4 [55680/60032 (93%)]\tLoss: 0.112443\n",
      "Train Epoch: 4 [56320/60032 (94%)]\tLoss: 0.112605\n",
      "Train Epoch: 4 [56960/60032 (95%)]\tLoss: 0.093293\n",
      "Train Epoch: 4 [57600/60032 (96%)]\tLoss: 0.062052\n",
      "Train Epoch: 4 [58240/60032 (97%)]\tLoss: 0.050211\n",
      "Train Epoch: 4 [58880/60032 (98%)]\tLoss: 0.218276\n",
      "Train Epoch: 4 [59520/60032 (99%)]\tLoss: 0.057471\n",
      "\n",
      "Test set: Average loss: 0.1258, Accuracy: 9640/10000 (96%)\n",
      "\n",
      "Train Epoch: 5 [0/60032 (0%)]\tLoss: 0.145243\n",
      "Train Epoch: 5 [640/60032 (1%)]\tLoss: 0.057843\n",
      "Train Epoch: 5 [1280/60032 (2%)]\tLoss: 0.150260\n",
      "Train Epoch: 5 [1920/60032 (3%)]\tLoss: 0.092441\n",
      "Train Epoch: 5 [2560/60032 (4%)]\tLoss: 0.097879\n",
      "Train Epoch: 5 [3200/60032 (5%)]\tLoss: 0.235506\n",
      "Train Epoch: 5 [3840/60032 (6%)]\tLoss: 0.130403\n",
      "Train Epoch: 5 [4480/60032 (7%)]\tLoss: 0.103829\n",
      "Train Epoch: 5 [5120/60032 (9%)]\tLoss: 0.135034\n",
      "Train Epoch: 5 [5760/60032 (10%)]\tLoss: 0.019331\n",
      "Train Epoch: 5 [6400/60032 (11%)]\tLoss: 0.074702\n",
      "Train Epoch: 5 [7040/60032 (12%)]\tLoss: 0.035817\n",
      "Train Epoch: 5 [7680/60032 (13%)]\tLoss: 0.128135\n",
      "Train Epoch: 5 [8320/60032 (14%)]\tLoss: 0.187938\n",
      "Train Epoch: 5 [8960/60032 (15%)]\tLoss: 0.177712\n",
      "Train Epoch: 5 [9600/60032 (16%)]\tLoss: 0.061014\n",
      "Train Epoch: 5 [10240/60032 (17%)]\tLoss: 0.139649\n",
      "Train Epoch: 5 [10880/60032 (18%)]\tLoss: 0.089482\n",
      "Train Epoch: 5 [11520/60032 (19%)]\tLoss: 0.244219\n",
      "Train Epoch: 5 [12160/60032 (20%)]\tLoss: 0.124161\n",
      "Train Epoch: 5 [12800/60032 (21%)]\tLoss: 0.100054\n",
      "Train Epoch: 5 [13440/60032 (22%)]\tLoss: 0.136315\n",
      "Train Epoch: 5 [14080/60032 (23%)]\tLoss: 0.053292\n",
      "Train Epoch: 5 [14720/60032 (25%)]\tLoss: 0.087977\n",
      "Train Epoch: 5 [15360/60032 (26%)]\tLoss: 0.075716\n",
      "Train Epoch: 5 [16000/60032 (27%)]\tLoss: 0.109410\n",
      "Train Epoch: 5 [16640/60032 (28%)]\tLoss: 0.132883\n",
      "Train Epoch: 5 [17280/60032 (29%)]\tLoss: 0.109679\n",
      "Train Epoch: 5 [17920/60032 (30%)]\tLoss: 0.052633\n",
      "Train Epoch: 5 [18560/60032 (31%)]\tLoss: 0.130702\n",
      "Train Epoch: 5 [19200/60032 (32%)]\tLoss: 0.261249\n",
      "Train Epoch: 5 [19840/60032 (33%)]\tLoss: 0.161252\n",
      "Train Epoch: 5 [20480/60032 (34%)]\tLoss: 0.135924\n",
      "Train Epoch: 5 [21120/60032 (35%)]\tLoss: 0.090107\n",
      "Train Epoch: 5 [21760/60032 (36%)]\tLoss: 0.085176\n",
      "Train Epoch: 5 [22400/60032 (37%)]\tLoss: 0.147368\n",
      "Train Epoch: 5 [23040/60032 (38%)]\tLoss: 0.049638\n",
      "Train Epoch: 5 [23680/60032 (39%)]\tLoss: 0.065676\n",
      "Train Epoch: 5 [24320/60032 (41%)]\tLoss: 0.088565\n",
      "Train Epoch: 5 [24960/60032 (42%)]\tLoss: 0.114925\n",
      "Train Epoch: 5 [25600/60032 (43%)]\tLoss: 0.061880\n",
      "Train Epoch: 5 [26240/60032 (44%)]\tLoss: 0.084800\n",
      "Train Epoch: 5 [26880/60032 (45%)]\tLoss: 0.319129\n",
      "Train Epoch: 5 [27520/60032 (46%)]\tLoss: 0.167424\n",
      "Train Epoch: 5 [28160/60032 (47%)]\tLoss: 0.063657\n",
      "Train Epoch: 5 [28800/60032 (48%)]\tLoss: 0.105180\n",
      "Train Epoch: 5 [29440/60032 (49%)]\tLoss: 0.150570\n",
      "Train Epoch: 5 [30080/60032 (50%)]\tLoss: 0.084981\n",
      "Train Epoch: 5 [30720/60032 (51%)]\tLoss: 0.062855\n",
      "Train Epoch: 5 [31360/60032 (52%)]\tLoss: 0.272485\n",
      "Train Epoch: 5 [32000/60032 (53%)]\tLoss: 0.026017\n",
      "Train Epoch: 5 [32640/60032 (54%)]\tLoss: 0.173775\n",
      "Train Epoch: 5 [33280/60032 (55%)]\tLoss: 0.179113\n",
      "Train Epoch: 5 [33920/60032 (57%)]\tLoss: 0.050750\n",
      "Train Epoch: 5 [34560/60032 (58%)]\tLoss: 0.155777\n",
      "Train Epoch: 5 [35200/60032 (59%)]\tLoss: 0.212838\n",
      "Train Epoch: 5 [35840/60032 (60%)]\tLoss: 0.127328\n",
      "Train Epoch: 5 [36480/60032 (61%)]\tLoss: 0.046898\n",
      "Train Epoch: 5 [37120/60032 (62%)]\tLoss: 0.387186\n",
      "Train Epoch: 5 [37760/60032 (63%)]\tLoss: 0.220548\n",
      "Train Epoch: 5 [38400/60032 (64%)]\tLoss: 0.214542\n",
      "Train Epoch: 5 [39040/60032 (65%)]\tLoss: 0.115999\n",
      "Train Epoch: 5 [39680/60032 (66%)]\tLoss: 0.138232\n",
      "Train Epoch: 5 [40320/60032 (67%)]\tLoss: 0.084952\n",
      "Train Epoch: 5 [40960/60032 (68%)]\tLoss: 0.154573\n",
      "Train Epoch: 5 [41600/60032 (69%)]\tLoss: 0.043849\n",
      "Train Epoch: 5 [42240/60032 (70%)]\tLoss: 0.064418\n",
      "Train Epoch: 5 [42880/60032 (71%)]\tLoss: 0.035489\n",
      "Train Epoch: 5 [43520/60032 (72%)]\tLoss: 0.078416\n",
      "Train Epoch: 5 [44160/60032 (74%)]\tLoss: 0.257131\n",
      "Train Epoch: 5 [44800/60032 (75%)]\tLoss: 0.062053\n",
      "Train Epoch: 5 [45440/60032 (76%)]\tLoss: 0.096704\n",
      "Train Epoch: 5 [46080/60032 (77%)]\tLoss: 0.103635\n",
      "Train Epoch: 5 [46720/60032 (78%)]\tLoss: 0.091433\n",
      "Train Epoch: 5 [47360/60032 (79%)]\tLoss: 0.042996\n",
      "Train Epoch: 5 [48000/60032 (80%)]\tLoss: 0.102142\n",
      "Train Epoch: 5 [48640/60032 (81%)]\tLoss: 0.036231\n",
      "Train Epoch: 5 [49280/60032 (82%)]\tLoss: 0.150659\n",
      "Train Epoch: 5 [49920/60032 (83%)]\tLoss: 0.045151\n",
      "Train Epoch: 5 [50560/60032 (84%)]\tLoss: 0.176631\n",
      "Train Epoch: 5 [51200/60032 (85%)]\tLoss: 0.164388\n",
      "Train Epoch: 5 [51840/60032 (86%)]\tLoss: 0.169622\n",
      "Train Epoch: 5 [52480/60032 (87%)]\tLoss: 0.211795\n",
      "Train Epoch: 5 [53120/60032 (88%)]\tLoss: 0.156798\n",
      "Train Epoch: 5 [53760/60032 (90%)]\tLoss: 0.036973\n",
      "Train Epoch: 5 [54400/60032 (91%)]\tLoss: 0.206083\n",
      "Train Epoch: 5 [55040/60032 (92%)]\tLoss: 0.070112\n",
      "Train Epoch: 5 [55680/60032 (93%)]\tLoss: 0.277050\n",
      "Train Epoch: 5 [56320/60032 (94%)]\tLoss: 0.047335\n",
      "Train Epoch: 5 [56960/60032 (95%)]\tLoss: 0.146306\n",
      "Train Epoch: 5 [57600/60032 (96%)]\tLoss: 0.054999\n",
      "Train Epoch: 5 [58240/60032 (97%)]\tLoss: 0.210025\n",
      "Train Epoch: 5 [58880/60032 (98%)]\tLoss: 0.250582\n",
      "Train Epoch: 5 [59520/60032 (99%)]\tLoss: 0.089936\n",
      "\n",
      "Test set: Average loss: 0.1129, Accuracy: 9655/10000 (97%)\n",
      "\n",
      "Train Epoch: 6 [0/60032 (0%)]\tLoss: 0.084893\n",
      "Train Epoch: 6 [640/60032 (1%)]\tLoss: 0.062513\n",
      "Train Epoch: 6 [1280/60032 (2%)]\tLoss: 0.147636\n",
      "Train Epoch: 6 [1920/60032 (3%)]\tLoss: 0.038573\n",
      "Train Epoch: 6 [2560/60032 (4%)]\tLoss: 0.314352\n",
      "Train Epoch: 6 [3200/60032 (5%)]\tLoss: 0.100655\n",
      "Train Epoch: 6 [3840/60032 (6%)]\tLoss: 0.141837\n",
      "Train Epoch: 6 [4480/60032 (7%)]\tLoss: 0.068307\n",
      "Train Epoch: 6 [5120/60032 (9%)]\tLoss: 0.118538\n",
      "Train Epoch: 6 [5760/60032 (10%)]\tLoss: 0.112320\n",
      "Train Epoch: 6 [6400/60032 (11%)]\tLoss: 0.085584\n",
      "Train Epoch: 6 [7040/60032 (12%)]\tLoss: 0.035100\n",
      "Train Epoch: 6 [7680/60032 (13%)]\tLoss: 0.205756\n",
      "Train Epoch: 6 [8320/60032 (14%)]\tLoss: 0.035393\n",
      "Train Epoch: 6 [8960/60032 (15%)]\tLoss: 0.051294\n",
      "Train Epoch: 6 [9600/60032 (16%)]\tLoss: 0.182776\n",
      "Train Epoch: 6 [10240/60032 (17%)]\tLoss: 0.087107\n",
      "Train Epoch: 6 [10880/60032 (18%)]\tLoss: 0.043989\n",
      "Train Epoch: 6 [11520/60032 (19%)]\tLoss: 0.014122\n",
      "Train Epoch: 6 [12160/60032 (20%)]\tLoss: 0.259999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 [12800/60032 (21%)]\tLoss: 0.068528\n",
      "Train Epoch: 6 [13440/60032 (22%)]\tLoss: 0.153918\n",
      "Train Epoch: 6 [14080/60032 (23%)]\tLoss: 0.226597\n",
      "Train Epoch: 6 [14720/60032 (25%)]\tLoss: 0.082808\n",
      "Train Epoch: 6 [15360/60032 (26%)]\tLoss: 0.096761\n",
      "Train Epoch: 6 [16000/60032 (27%)]\tLoss: 0.138324\n",
      "Train Epoch: 6 [16640/60032 (28%)]\tLoss: 0.071043\n",
      "Train Epoch: 6 [17280/60032 (29%)]\tLoss: 0.066943\n",
      "Train Epoch: 6 [17920/60032 (30%)]\tLoss: 0.195498\n",
      "Train Epoch: 6 [18560/60032 (31%)]\tLoss: 0.040779\n",
      "Train Epoch: 6 [19200/60032 (32%)]\tLoss: 0.099601\n",
      "Train Epoch: 6 [19840/60032 (33%)]\tLoss: 0.187817\n",
      "Train Epoch: 6 [20480/60032 (34%)]\tLoss: 0.161698\n",
      "Train Epoch: 6 [21120/60032 (35%)]\tLoss: 0.106130\n",
      "Train Epoch: 6 [21760/60032 (36%)]\tLoss: 0.018616\n",
      "Train Epoch: 6 [22400/60032 (37%)]\tLoss: 0.044066\n",
      "Train Epoch: 6 [23040/60032 (38%)]\tLoss: 0.026581\n",
      "Train Epoch: 6 [23680/60032 (39%)]\tLoss: 0.067570\n",
      "Train Epoch: 6 [24320/60032 (41%)]\tLoss: 0.027819\n",
      "Train Epoch: 6 [24960/60032 (42%)]\tLoss: 0.082409\n",
      "Train Epoch: 6 [25600/60032 (43%)]\tLoss: 0.054098\n",
      "Train Epoch: 6 [26240/60032 (44%)]\tLoss: 0.173316\n",
      "Train Epoch: 6 [26880/60032 (45%)]\tLoss: 0.106207\n",
      "Train Epoch: 6 [27520/60032 (46%)]\tLoss: 0.022165\n",
      "Train Epoch: 6 [28160/60032 (47%)]\tLoss: 0.118082\n",
      "Train Epoch: 6 [28800/60032 (48%)]\tLoss: 0.180075\n",
      "Train Epoch: 6 [29440/60032 (49%)]\tLoss: 0.186646\n",
      "Train Epoch: 6 [30080/60032 (50%)]\tLoss: 0.275385\n",
      "Train Epoch: 6 [30720/60032 (51%)]\tLoss: 0.196286\n",
      "Train Epoch: 6 [31360/60032 (52%)]\tLoss: 0.170771\n",
      "Train Epoch: 6 [32000/60032 (53%)]\tLoss: 0.224272\n",
      "Train Epoch: 6 [32640/60032 (54%)]\tLoss: 0.043048\n",
      "Train Epoch: 6 [33280/60032 (55%)]\tLoss: 0.039262\n",
      "Train Epoch: 6 [33920/60032 (57%)]\tLoss: 0.077154\n",
      "Train Epoch: 6 [34560/60032 (58%)]\tLoss: 0.093620\n",
      "Train Epoch: 6 [35200/60032 (59%)]\tLoss: 0.039624\n",
      "Train Epoch: 6 [35840/60032 (60%)]\tLoss: 0.051487\n",
      "Train Epoch: 6 [36480/60032 (61%)]\tLoss: 0.205105\n",
      "Train Epoch: 6 [37120/60032 (62%)]\tLoss: 0.025962\n",
      "Train Epoch: 6 [37760/60032 (63%)]\tLoss: 0.147381\n",
      "Train Epoch: 6 [38400/60032 (64%)]\tLoss: 0.118696\n",
      "Train Epoch: 6 [39040/60032 (65%)]\tLoss: 0.030890\n",
      "Train Epoch: 6 [39680/60032 (66%)]\tLoss: 0.118940\n",
      "Train Epoch: 6 [40320/60032 (67%)]\tLoss: 0.210051\n",
      "Train Epoch: 6 [40960/60032 (68%)]\tLoss: 0.056209\n",
      "Train Epoch: 6 [41600/60032 (69%)]\tLoss: 0.139111\n",
      "Train Epoch: 6 [42240/60032 (70%)]\tLoss: 0.063975\n",
      "Train Epoch: 6 [42880/60032 (71%)]\tLoss: 0.031699\n",
      "Train Epoch: 6 [43520/60032 (72%)]\tLoss: 0.072094\n",
      "Train Epoch: 6 [44160/60032 (74%)]\tLoss: 0.094287\n",
      "Train Epoch: 6 [44800/60032 (75%)]\tLoss: 0.176715\n",
      "Train Epoch: 6 [45440/60032 (76%)]\tLoss: 0.100287\n",
      "Train Epoch: 6 [46080/60032 (77%)]\tLoss: 0.046351\n",
      "Train Epoch: 6 [46720/60032 (78%)]\tLoss: 0.160153\n",
      "Train Epoch: 6 [47360/60032 (79%)]\tLoss: 0.107498\n",
      "Train Epoch: 6 [48000/60032 (80%)]\tLoss: 0.022588\n",
      "Train Epoch: 6 [48640/60032 (81%)]\tLoss: 0.053360\n",
      "Train Epoch: 6 [49280/60032 (82%)]\tLoss: 0.042957\n",
      "Train Epoch: 6 [49920/60032 (83%)]\tLoss: 0.198350\n",
      "Train Epoch: 6 [50560/60032 (84%)]\tLoss: 0.167611\n",
      "Train Epoch: 6 [51200/60032 (85%)]\tLoss: 0.155222\n",
      "Train Epoch: 6 [51840/60032 (86%)]\tLoss: 0.118700\n",
      "Train Epoch: 6 [52480/60032 (87%)]\tLoss: 0.192448\n",
      "Train Epoch: 6 [53120/60032 (88%)]\tLoss: 0.040245\n",
      "Train Epoch: 6 [53760/60032 (90%)]\tLoss: 0.153581\n",
      "Train Epoch: 6 [54400/60032 (91%)]\tLoss: 0.061120\n",
      "Train Epoch: 6 [55040/60032 (92%)]\tLoss: 0.044190\n",
      "Train Epoch: 6 [55680/60032 (93%)]\tLoss: 0.049675\n",
      "Train Epoch: 6 [56320/60032 (94%)]\tLoss: 0.086484\n",
      "Train Epoch: 6 [56960/60032 (95%)]\tLoss: 0.026443\n",
      "Train Epoch: 6 [57600/60032 (96%)]\tLoss: 0.056718\n",
      "Train Epoch: 6 [58240/60032 (97%)]\tLoss: 0.089040\n",
      "Train Epoch: 6 [58880/60032 (98%)]\tLoss: 0.084137\n",
      "Train Epoch: 6 [59520/60032 (99%)]\tLoss: 0.031042\n",
      "\n",
      "Test set: Average loss: 0.1146, Accuracy: 9634/10000 (96%)\n",
      "\n",
      "Train Epoch: 7 [0/60032 (0%)]\tLoss: 0.077317\n",
      "Train Epoch: 7 [640/60032 (1%)]\tLoss: 0.147307\n",
      "Train Epoch: 7 [1280/60032 (2%)]\tLoss: 0.066956\n",
      "Train Epoch: 7 [1920/60032 (3%)]\tLoss: 0.060906\n",
      "Train Epoch: 7 [2560/60032 (4%)]\tLoss: 0.053910\n",
      "Train Epoch: 7 [3200/60032 (5%)]\tLoss: 0.049444\n",
      "Train Epoch: 7 [3840/60032 (6%)]\tLoss: 0.084655\n",
      "Train Epoch: 7 [4480/60032 (7%)]\tLoss: 0.080534\n",
      "Train Epoch: 7 [5120/60032 (9%)]\tLoss: 0.086278\n",
      "Train Epoch: 7 [5760/60032 (10%)]\tLoss: 0.093472\n",
      "Train Epoch: 7 [6400/60032 (11%)]\tLoss: 0.035596\n",
      "Train Epoch: 7 [7040/60032 (12%)]\tLoss: 0.079968\n",
      "Train Epoch: 7 [7680/60032 (13%)]\tLoss: 0.103206\n",
      "Train Epoch: 7 [8320/60032 (14%)]\tLoss: 0.041779\n",
      "Train Epoch: 7 [8960/60032 (15%)]\tLoss: 0.144662\n",
      "Train Epoch: 7 [9600/60032 (16%)]\tLoss: 0.118022\n",
      "Train Epoch: 7 [10240/60032 (17%)]\tLoss: 0.058378\n",
      "Train Epoch: 7 [10880/60032 (18%)]\tLoss: 0.117931\n",
      "Train Epoch: 7 [11520/60032 (19%)]\tLoss: 0.089223\n",
      "Train Epoch: 7 [12160/60032 (20%)]\tLoss: 0.132696\n",
      "Train Epoch: 7 [12800/60032 (21%)]\tLoss: 0.045870\n",
      "Train Epoch: 7 [13440/60032 (22%)]\tLoss: 0.040592\n",
      "Train Epoch: 7 [14080/60032 (23%)]\tLoss: 0.126153\n",
      "Train Epoch: 7 [14720/60032 (25%)]\tLoss: 0.052123\n",
      "Train Epoch: 7 [15360/60032 (26%)]\tLoss: 0.079280\n",
      "Train Epoch: 7 [16000/60032 (27%)]\tLoss: 0.102702\n",
      "Train Epoch: 7 [16640/60032 (28%)]\tLoss: 0.138671\n",
      "Train Epoch: 7 [17280/60032 (29%)]\tLoss: 0.210125\n",
      "Train Epoch: 7 [17920/60032 (30%)]\tLoss: 0.166169\n",
      "Train Epoch: 7 [18560/60032 (31%)]\tLoss: 0.156680\n",
      "Train Epoch: 7 [19200/60032 (32%)]\tLoss: 0.154306\n",
      "Train Epoch: 7 [19840/60032 (33%)]\tLoss: 0.158290\n",
      "Train Epoch: 7 [20480/60032 (34%)]\tLoss: 0.187968\n",
      "Train Epoch: 7 [21120/60032 (35%)]\tLoss: 0.093861\n",
      "Train Epoch: 7 [21760/60032 (36%)]\tLoss: 0.094680\n",
      "Train Epoch: 7 [22400/60032 (37%)]\tLoss: 0.044824\n",
      "Train Epoch: 7 [23040/60032 (38%)]\tLoss: 0.091170\n",
      "Train Epoch: 7 [23680/60032 (39%)]\tLoss: 0.037346\n",
      "Train Epoch: 7 [24320/60032 (41%)]\tLoss: 0.019266\n",
      "Train Epoch: 7 [24960/60032 (42%)]\tLoss: 0.094897\n",
      "Train Epoch: 7 [25600/60032 (43%)]\tLoss: 0.043202\n",
      "Train Epoch: 7 [26240/60032 (44%)]\tLoss: 0.028548\n",
      "Train Epoch: 7 [26880/60032 (45%)]\tLoss: 0.058877\n",
      "Train Epoch: 7 [27520/60032 (46%)]\tLoss: 0.078562\n",
      "Train Epoch: 7 [28160/60032 (47%)]\tLoss: 0.069715\n",
      "Train Epoch: 7 [28800/60032 (48%)]\tLoss: 0.017410\n",
      "Train Epoch: 7 [29440/60032 (49%)]\tLoss: 0.026560\n",
      "Train Epoch: 7 [30080/60032 (50%)]\tLoss: 0.194539\n",
      "Train Epoch: 7 [30720/60032 (51%)]\tLoss: 0.151766\n",
      "Train Epoch: 7 [31360/60032 (52%)]\tLoss: 0.163350\n",
      "Train Epoch: 7 [32000/60032 (53%)]\tLoss: 0.080753\n",
      "Train Epoch: 7 [32640/60032 (54%)]\tLoss: 0.102709\n",
      "Train Epoch: 7 [33280/60032 (55%)]\tLoss: 0.068441\n",
      "Train Epoch: 7 [33920/60032 (57%)]\tLoss: 0.098688\n",
      "Train Epoch: 7 [34560/60032 (58%)]\tLoss: 0.210829\n",
      "Train Epoch: 7 [35200/60032 (59%)]\tLoss: 0.072235\n",
      "Train Epoch: 7 [35840/60032 (60%)]\tLoss: 0.094677\n",
      "Train Epoch: 7 [36480/60032 (61%)]\tLoss: 0.072312\n",
      "Train Epoch: 7 [37120/60032 (62%)]\tLoss: 0.045928\n",
      "Train Epoch: 7 [37760/60032 (63%)]\tLoss: 0.137342\n",
      "Train Epoch: 7 [38400/60032 (64%)]\tLoss: 0.142288\n",
      "Train Epoch: 7 [39040/60032 (65%)]\tLoss: 0.036859\n",
      "Train Epoch: 7 [39680/60032 (66%)]\tLoss: 0.022986\n",
      "Train Epoch: 7 [40320/60032 (67%)]\tLoss: 0.092737\n",
      "Train Epoch: 7 [40960/60032 (68%)]\tLoss: 0.080618\n",
      "Train Epoch: 7 [41600/60032 (69%)]\tLoss: 0.094651\n",
      "Train Epoch: 7 [42240/60032 (70%)]\tLoss: 0.214511\n",
      "Train Epoch: 7 [42880/60032 (71%)]\tLoss: 0.066805\n",
      "Train Epoch: 7 [43520/60032 (72%)]\tLoss: 0.069670\n",
      "Train Epoch: 7 [44160/60032 (74%)]\tLoss: 0.210928\n",
      "Train Epoch: 7 [44800/60032 (75%)]\tLoss: 0.143709\n",
      "Train Epoch: 7 [45440/60032 (76%)]\tLoss: 0.065062\n",
      "Train Epoch: 7 [46080/60032 (77%)]\tLoss: 0.096673\n",
      "Train Epoch: 7 [46720/60032 (78%)]\tLoss: 0.148912\n",
      "Train Epoch: 7 [47360/60032 (79%)]\tLoss: 0.051710\n",
      "Train Epoch: 7 [48000/60032 (80%)]\tLoss: 0.066956\n",
      "Train Epoch: 7 [48640/60032 (81%)]\tLoss: 0.159801\n",
      "Train Epoch: 7 [49280/60032 (82%)]\tLoss: 0.025677\n",
      "Train Epoch: 7 [49920/60032 (83%)]\tLoss: 0.072794\n",
      "Train Epoch: 7 [50560/60032 (84%)]\tLoss: 0.029898\n",
      "Train Epoch: 7 [51200/60032 (85%)]\tLoss: 0.115473\n",
      "Train Epoch: 7 [51840/60032 (86%)]\tLoss: 0.197928\n",
      "Train Epoch: 7 [52480/60032 (87%)]\tLoss: 0.054751\n",
      "Train Epoch: 7 [53120/60032 (88%)]\tLoss: 0.010371\n",
      "Train Epoch: 7 [53760/60032 (90%)]\tLoss: 0.032231\n",
      "Train Epoch: 7 [54400/60032 (91%)]\tLoss: 0.049361\n",
      "Train Epoch: 7 [55040/60032 (92%)]\tLoss: 0.066704\n",
      "Train Epoch: 7 [55680/60032 (93%)]\tLoss: 0.038440\n",
      "Train Epoch: 7 [56320/60032 (94%)]\tLoss: 0.103746\n",
      "Train Epoch: 7 [56960/60032 (95%)]\tLoss: 0.185877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [57600/60032 (96%)]\tLoss: 0.124234\n",
      "Train Epoch: 7 [58240/60032 (97%)]\tLoss: 0.040691\n",
      "Train Epoch: 7 [58880/60032 (98%)]\tLoss: 0.235044\n",
      "Train Epoch: 7 [59520/60032 (99%)]\tLoss: 0.083562\n",
      "\n",
      "Test set: Average loss: 0.0953, Accuracy: 9699/10000 (97%)\n",
      "\n",
      "Train Epoch: 8 [0/60032 (0%)]\tLoss: 0.171805\n",
      "Train Epoch: 8 [640/60032 (1%)]\tLoss: 0.208774\n",
      "Train Epoch: 8 [1280/60032 (2%)]\tLoss: 0.054451\n",
      "Train Epoch: 8 [1920/60032 (3%)]\tLoss: 0.140121\n",
      "Train Epoch: 8 [2560/60032 (4%)]\tLoss: 0.065116\n",
      "Train Epoch: 8 [3200/60032 (5%)]\tLoss: 0.033576\n",
      "Train Epoch: 8 [3840/60032 (6%)]\tLoss: 0.026378\n",
      "Train Epoch: 8 [4480/60032 (7%)]\tLoss: 0.054831\n",
      "Train Epoch: 8 [5120/60032 (9%)]\tLoss: 0.020852\n",
      "Train Epoch: 8 [5760/60032 (10%)]\tLoss: 0.104904\n",
      "Train Epoch: 8 [6400/60032 (11%)]\tLoss: 0.068007\n",
      "Train Epoch: 8 [7040/60032 (12%)]\tLoss: 0.057289\n",
      "Train Epoch: 8 [7680/60032 (13%)]\tLoss: 0.010269\n",
      "Train Epoch: 8 [8320/60032 (14%)]\tLoss: 0.025279\n",
      "Train Epoch: 8 [8960/60032 (15%)]\tLoss: 0.175086\n",
      "Train Epoch: 8 [9600/60032 (16%)]\tLoss: 0.100893\n",
      "Train Epoch: 8 [10240/60032 (17%)]\tLoss: 0.060449\n",
      "Train Epoch: 8 [10880/60032 (18%)]\tLoss: 0.008801\n",
      "Train Epoch: 8 [11520/60032 (19%)]\tLoss: 0.139104\n",
      "Train Epoch: 8 [12160/60032 (20%)]\tLoss: 0.112177\n",
      "Train Epoch: 8 [12800/60032 (21%)]\tLoss: 0.090792\n",
      "Train Epoch: 8 [13440/60032 (22%)]\tLoss: 0.136972\n",
      "Train Epoch: 8 [14080/60032 (23%)]\tLoss: 0.114908\n",
      "Train Epoch: 8 [14720/60032 (25%)]\tLoss: 0.057434\n",
      "Train Epoch: 8 [15360/60032 (26%)]\tLoss: 0.034886\n",
      "Train Epoch: 8 [16000/60032 (27%)]\tLoss: 0.042462\n",
      "Train Epoch: 8 [16640/60032 (28%)]\tLoss: 0.021330\n",
      "Train Epoch: 8 [17280/60032 (29%)]\tLoss: 0.075379\n",
      "Train Epoch: 8 [17920/60032 (30%)]\tLoss: 0.048849\n",
      "Train Epoch: 8 [18560/60032 (31%)]\tLoss: 0.058556\n",
      "Train Epoch: 8 [19200/60032 (32%)]\tLoss: 0.030174\n",
      "Train Epoch: 8 [19840/60032 (33%)]\tLoss: 0.010859\n",
      "Train Epoch: 8 [20480/60032 (34%)]\tLoss: 0.050358\n",
      "Train Epoch: 8 [21120/60032 (35%)]\tLoss: 0.138973\n",
      "Train Epoch: 8 [21760/60032 (36%)]\tLoss: 0.123150\n",
      "Train Epoch: 8 [22400/60032 (37%)]\tLoss: 0.124858\n",
      "Train Epoch: 8 [23040/60032 (38%)]\tLoss: 0.077012\n",
      "Train Epoch: 8 [23680/60032 (39%)]\tLoss: 0.077998\n",
      "Train Epoch: 8 [24320/60032 (41%)]\tLoss: 0.035743\n",
      "Train Epoch: 8 [24960/60032 (42%)]\tLoss: 0.081035\n",
      "Train Epoch: 8 [25600/60032 (43%)]\tLoss: 0.137413\n",
      "Train Epoch: 8 [26240/60032 (44%)]\tLoss: 0.032997\n",
      "Train Epoch: 8 [26880/60032 (45%)]\tLoss: 0.095248\n",
      "Train Epoch: 8 [27520/60032 (46%)]\tLoss: 0.050260\n",
      "Train Epoch: 8 [28160/60032 (47%)]\tLoss: 0.135695\n",
      "Train Epoch: 8 [28800/60032 (48%)]\tLoss: 0.044031\n",
      "Train Epoch: 8 [29440/60032 (49%)]\tLoss: 0.080626\n",
      "Train Epoch: 8 [30080/60032 (50%)]\tLoss: 0.240924\n",
      "Train Epoch: 8 [30720/60032 (51%)]\tLoss: 0.102043\n",
      "Train Epoch: 8 [31360/60032 (52%)]\tLoss: 0.024074\n",
      "Train Epoch: 8 [32000/60032 (53%)]\tLoss: 0.064809\n",
      "Train Epoch: 8 [32640/60032 (54%)]\tLoss: 0.029790\n",
      "Train Epoch: 8 [33280/60032 (55%)]\tLoss: 0.135986\n",
      "Train Epoch: 8 [33920/60032 (57%)]\tLoss: 0.097424\n",
      "Train Epoch: 8 [34560/60032 (58%)]\tLoss: 0.060486\n",
      "Train Epoch: 8 [35200/60032 (59%)]\tLoss: 0.203197\n",
      "Train Epoch: 8 [35840/60032 (60%)]\tLoss: 0.050473\n",
      "Train Epoch: 8 [36480/60032 (61%)]\tLoss: 0.012426\n",
      "Train Epoch: 8 [37120/60032 (62%)]\tLoss: 0.064880\n",
      "Train Epoch: 8 [37760/60032 (63%)]\tLoss: 0.035489\n",
      "Train Epoch: 8 [38400/60032 (64%)]\tLoss: 0.074162\n",
      "Train Epoch: 8 [39040/60032 (65%)]\tLoss: 0.139831\n",
      "Train Epoch: 8 [39680/60032 (66%)]\tLoss: 0.039778\n",
      "Train Epoch: 8 [40320/60032 (67%)]\tLoss: 0.103133\n",
      "Train Epoch: 8 [40960/60032 (68%)]\tLoss: 0.110067\n",
      "Train Epoch: 8 [41600/60032 (69%)]\tLoss: 0.024287\n",
      "Train Epoch: 8 [42240/60032 (70%)]\tLoss: 0.158846\n",
      "Train Epoch: 8 [42880/60032 (71%)]\tLoss: 0.042727\n",
      "Train Epoch: 8 [43520/60032 (72%)]\tLoss: 0.125299\n",
      "Train Epoch: 8 [44160/60032 (74%)]\tLoss: 0.002869\n",
      "Train Epoch: 8 [44800/60032 (75%)]\tLoss: 0.180565\n",
      "Train Epoch: 8 [45440/60032 (76%)]\tLoss: 0.212511\n",
      "Train Epoch: 8 [46080/60032 (77%)]\tLoss: 0.037474\n",
      "Train Epoch: 8 [46720/60032 (78%)]\tLoss: 0.065305\n",
      "Train Epoch: 8 [47360/60032 (79%)]\tLoss: 0.173989\n",
      "Train Epoch: 8 [48000/60032 (80%)]\tLoss: 0.035737\n",
      "Train Epoch: 8 [48640/60032 (81%)]\tLoss: 0.128916\n",
      "Train Epoch: 8 [49280/60032 (82%)]\tLoss: 0.081526\n",
      "Train Epoch: 8 [49920/60032 (83%)]\tLoss: 0.012268\n",
      "Train Epoch: 8 [50560/60032 (84%)]\tLoss: 0.215020\n",
      "Train Epoch: 8 [51200/60032 (85%)]\tLoss: 0.024895\n",
      "Train Epoch: 8 [51840/60032 (86%)]\tLoss: 0.033064\n",
      "Train Epoch: 8 [52480/60032 (87%)]\tLoss: 0.048991\n",
      "Train Epoch: 8 [53120/60032 (88%)]\tLoss: 0.005795\n",
      "Train Epoch: 8 [53760/60032 (90%)]\tLoss: 0.020217\n",
      "Train Epoch: 8 [54400/60032 (91%)]\tLoss: 0.054190\n",
      "Train Epoch: 8 [55040/60032 (92%)]\tLoss: 0.063491\n",
      "Train Epoch: 8 [55680/60032 (93%)]\tLoss: 0.103594\n",
      "Train Epoch: 8 [56320/60032 (94%)]\tLoss: 0.037291\n",
      "Train Epoch: 8 [56960/60032 (95%)]\tLoss: 0.052159\n",
      "Train Epoch: 8 [57600/60032 (96%)]\tLoss: 0.077838\n",
      "Train Epoch: 8 [58240/60032 (97%)]\tLoss: 0.083479\n",
      "Train Epoch: 8 [58880/60032 (98%)]\tLoss: 0.053041\n",
      "Train Epoch: 8 [59520/60032 (99%)]\tLoss: 0.051191\n",
      "\n",
      "Test set: Average loss: 0.0886, Accuracy: 9701/10000 (97%)\n",
      "\n",
      "Train Epoch: 9 [0/60032 (0%)]\tLoss: 0.141673\n",
      "Train Epoch: 9 [640/60032 (1%)]\tLoss: 0.138779\n",
      "Train Epoch: 9 [1280/60032 (2%)]\tLoss: 0.035884\n",
      "Train Epoch: 9 [1920/60032 (3%)]\tLoss: 0.022482\n",
      "Train Epoch: 9 [2560/60032 (4%)]\tLoss: 0.008142\n",
      "Train Epoch: 9 [3200/60032 (5%)]\tLoss: 0.034167\n",
      "Train Epoch: 9 [3840/60032 (6%)]\tLoss: 0.069139\n",
      "Train Epoch: 9 [4480/60032 (7%)]\tLoss: 0.157036\n",
      "Train Epoch: 9 [5120/60032 (9%)]\tLoss: 0.040653\n",
      "Train Epoch: 9 [5760/60032 (10%)]\tLoss: 0.144732\n",
      "Train Epoch: 9 [6400/60032 (11%)]\tLoss: 0.141603\n",
      "Train Epoch: 9 [7040/60032 (12%)]\tLoss: 0.075939\n",
      "Train Epoch: 9 [7680/60032 (13%)]\tLoss: 0.076697\n",
      "Train Epoch: 9 [8320/60032 (14%)]\tLoss: 0.095430\n",
      "Train Epoch: 9 [8960/60032 (15%)]\tLoss: 0.145135\n",
      "Train Epoch: 9 [9600/60032 (16%)]\tLoss: 0.206655\n",
      "Train Epoch: 9 [10240/60032 (17%)]\tLoss: 0.042573\n",
      "Train Epoch: 9 [10880/60032 (18%)]\tLoss: 0.159359\n",
      "Train Epoch: 9 [11520/60032 (19%)]\tLoss: 0.078998\n",
      "Train Epoch: 9 [12160/60032 (20%)]\tLoss: 0.073814\n",
      "Train Epoch: 9 [12800/60032 (21%)]\tLoss: 0.116927\n",
      "Train Epoch: 9 [13440/60032 (22%)]\tLoss: 0.062398\n",
      "Train Epoch: 9 [14080/60032 (23%)]\tLoss: 0.089178\n",
      "Train Epoch: 9 [14720/60032 (25%)]\tLoss: 0.023630\n",
      "Train Epoch: 9 [15360/60032 (26%)]\tLoss: 0.022123\n",
      "Train Epoch: 9 [16000/60032 (27%)]\tLoss: 0.065261\n",
      "Train Epoch: 9 [16640/60032 (28%)]\tLoss: 0.203751\n",
      "Train Epoch: 9 [17280/60032 (29%)]\tLoss: 0.063396\n",
      "Train Epoch: 9 [17920/60032 (30%)]\tLoss: 0.120476\n",
      "Train Epoch: 9 [18560/60032 (31%)]\tLoss: 0.027295\n",
      "Train Epoch: 9 [19200/60032 (32%)]\tLoss: 0.045871\n",
      "Train Epoch: 9 [19840/60032 (33%)]\tLoss: 0.014039\n",
      "Train Epoch: 9 [20480/60032 (34%)]\tLoss: 0.085074\n",
      "Train Epoch: 9 [21120/60032 (35%)]\tLoss: 0.071303\n",
      "Train Epoch: 9 [21760/60032 (36%)]\tLoss: 0.092794\n",
      "Train Epoch: 9 [22400/60032 (37%)]\tLoss: 0.016283\n",
      "Train Epoch: 9 [23040/60032 (38%)]\tLoss: 0.026761\n",
      "Train Epoch: 9 [23680/60032 (39%)]\tLoss: 0.113662\n",
      "Train Epoch: 9 [24320/60032 (41%)]\tLoss: 0.167562\n",
      "Train Epoch: 9 [24960/60032 (42%)]\tLoss: 0.127829\n",
      "Train Epoch: 9 [25600/60032 (43%)]\tLoss: 0.077425\n",
      "Train Epoch: 9 [26240/60032 (44%)]\tLoss: 0.057596\n",
      "Train Epoch: 9 [26880/60032 (45%)]\tLoss: 0.067982\n",
      "Train Epoch: 9 [27520/60032 (46%)]\tLoss: 0.075427\n",
      "Train Epoch: 9 [28160/60032 (47%)]\tLoss: 0.048628\n",
      "Train Epoch: 9 [28800/60032 (48%)]\tLoss: 0.035086\n",
      "Train Epoch: 9 [29440/60032 (49%)]\tLoss: 0.102260\n",
      "Train Epoch: 9 [30080/60032 (50%)]\tLoss: 0.165408\n",
      "Train Epoch: 9 [30720/60032 (51%)]\tLoss: 0.145020\n",
      "Train Epoch: 9 [31360/60032 (52%)]\tLoss: 0.072043\n",
      "Train Epoch: 9 [32000/60032 (53%)]\tLoss: 0.021570\n",
      "Train Epoch: 9 [32640/60032 (54%)]\tLoss: 0.070497\n",
      "Train Epoch: 9 [33280/60032 (55%)]\tLoss: 0.040865\n",
      "Train Epoch: 9 [33920/60032 (57%)]\tLoss: 0.192477\n",
      "Train Epoch: 9 [34560/60032 (58%)]\tLoss: 0.158230\n",
      "Train Epoch: 9 [35200/60032 (59%)]\tLoss: 0.086076\n",
      "Train Epoch: 9 [35840/60032 (60%)]\tLoss: 0.040930\n",
      "Train Epoch: 9 [36480/60032 (61%)]\tLoss: 0.151722\n",
      "Train Epoch: 9 [37120/60032 (62%)]\tLoss: 0.015969\n",
      "Train Epoch: 9 [37760/60032 (63%)]\tLoss: 0.094539\n",
      "Train Epoch: 9 [38400/60032 (64%)]\tLoss: 0.049115\n",
      "Train Epoch: 9 [39040/60032 (65%)]\tLoss: 0.039011\n",
      "Train Epoch: 9 [39680/60032 (66%)]\tLoss: 0.016346\n",
      "Train Epoch: 9 [40320/60032 (67%)]\tLoss: 0.014619\n",
      "Train Epoch: 9 [40960/60032 (68%)]\tLoss: 0.058042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [41600/60032 (69%)]\tLoss: 0.259114\n",
      "Train Epoch: 9 [42240/60032 (70%)]\tLoss: 0.045182\n",
      "Train Epoch: 9 [42880/60032 (71%)]\tLoss: 0.187853\n",
      "Train Epoch: 9 [43520/60032 (72%)]\tLoss: 0.066809\n",
      "Train Epoch: 9 [44160/60032 (74%)]\tLoss: 0.481488\n",
      "Train Epoch: 9 [44800/60032 (75%)]\tLoss: 0.039690\n",
      "Train Epoch: 9 [45440/60032 (76%)]\tLoss: 0.168031\n",
      "Train Epoch: 9 [46080/60032 (77%)]\tLoss: 0.091663\n",
      "Train Epoch: 9 [46720/60032 (78%)]\tLoss: 0.088382\n",
      "Train Epoch: 9 [47360/60032 (79%)]\tLoss: 0.018828\n",
      "Train Epoch: 9 [48000/60032 (80%)]\tLoss: 0.040167\n",
      "Train Epoch: 9 [48640/60032 (81%)]\tLoss: 0.075106\n",
      "Train Epoch: 9 [49280/60032 (82%)]\tLoss: 0.020438\n",
      "Train Epoch: 9 [49920/60032 (83%)]\tLoss: 0.103481\n",
      "Train Epoch: 9 [50560/60032 (84%)]\tLoss: 0.070574\n",
      "Train Epoch: 9 [51200/60032 (85%)]\tLoss: 0.277811\n",
      "Train Epoch: 9 [51840/60032 (86%)]\tLoss: 0.096832\n",
      "Train Epoch: 9 [52480/60032 (87%)]\tLoss: 0.117702\n",
      "Train Epoch: 9 [53120/60032 (88%)]\tLoss: 0.004692\n",
      "Train Epoch: 9 [53760/60032 (90%)]\tLoss: 0.024109\n",
      "Train Epoch: 9 [54400/60032 (91%)]\tLoss: 0.054269\n",
      "Train Epoch: 9 [55040/60032 (92%)]\tLoss: 0.107052\n",
      "Train Epoch: 9 [55680/60032 (93%)]\tLoss: 0.110650\n",
      "Train Epoch: 9 [56320/60032 (94%)]\tLoss: 0.038077\n",
      "Train Epoch: 9 [56960/60032 (95%)]\tLoss: 0.039547\n",
      "Train Epoch: 9 [57600/60032 (96%)]\tLoss: 0.106201\n",
      "Train Epoch: 9 [58240/60032 (97%)]\tLoss: 0.055205\n",
      "Train Epoch: 9 [58880/60032 (98%)]\tLoss: 0.094812\n",
      "Train Epoch: 9 [59520/60032 (99%)]\tLoss: 0.041646\n",
      "\n",
      "Test set: Average loss: 0.0823, Accuracy: 9736/10000 (97%)\n",
      "\n",
      "Train Epoch: 10 [0/60032 (0%)]\tLoss: 0.007542\n",
      "Train Epoch: 10 [640/60032 (1%)]\tLoss: 0.110759\n",
      "Train Epoch: 10 [1280/60032 (2%)]\tLoss: 0.053773\n",
      "Train Epoch: 10 [1920/60032 (3%)]\tLoss: 0.036831\n",
      "Train Epoch: 10 [2560/60032 (4%)]\tLoss: 0.225646\n",
      "Train Epoch: 10 [3200/60032 (5%)]\tLoss: 0.094945\n",
      "Train Epoch: 10 [3840/60032 (6%)]\tLoss: 0.074186\n",
      "Train Epoch: 10 [4480/60032 (7%)]\tLoss: 0.104056\n",
      "Train Epoch: 10 [5120/60032 (9%)]\tLoss: 0.122870\n",
      "Train Epoch: 10 [5760/60032 (10%)]\tLoss: 0.027995\n",
      "Train Epoch: 10 [6400/60032 (11%)]\tLoss: 0.053042\n",
      "Train Epoch: 10 [7040/60032 (12%)]\tLoss: 0.028101\n",
      "Train Epoch: 10 [7680/60032 (13%)]\tLoss: 0.015632\n",
      "Train Epoch: 10 [8320/60032 (14%)]\tLoss: 0.185963\n",
      "Train Epoch: 10 [8960/60032 (15%)]\tLoss: 0.107901\n",
      "Train Epoch: 10 [9600/60032 (16%)]\tLoss: 0.110188\n",
      "Train Epoch: 10 [10240/60032 (17%)]\tLoss: 0.042809\n",
      "Train Epoch: 10 [10880/60032 (18%)]\tLoss: 0.079166\n",
      "Train Epoch: 10 [11520/60032 (19%)]\tLoss: 0.087806\n",
      "Train Epoch: 10 [12160/60032 (20%)]\tLoss: 0.070165\n",
      "Train Epoch: 10 [12800/60032 (21%)]\tLoss: 0.030017\n",
      "Train Epoch: 10 [13440/60032 (22%)]\tLoss: 0.077080\n",
      "Train Epoch: 10 [14080/60032 (23%)]\tLoss: 0.060499\n",
      "Train Epoch: 10 [14720/60032 (25%)]\tLoss: 0.033318\n",
      "Train Epoch: 10 [15360/60032 (26%)]\tLoss: 0.046113\n",
      "Train Epoch: 10 [16000/60032 (27%)]\tLoss: 0.238864\n",
      "Train Epoch: 10 [16640/60032 (28%)]\tLoss: 0.096521\n",
      "Train Epoch: 10 [17280/60032 (29%)]\tLoss: 0.007736\n",
      "Train Epoch: 10 [17920/60032 (30%)]\tLoss: 0.064806\n",
      "Train Epoch: 10 [18560/60032 (31%)]\tLoss: 0.186881\n",
      "Train Epoch: 10 [19200/60032 (32%)]\tLoss: 0.042959\n",
      "Train Epoch: 10 [19840/60032 (33%)]\tLoss: 0.057230\n",
      "Train Epoch: 10 [20480/60032 (34%)]\tLoss: 0.024485\n",
      "Train Epoch: 10 [21120/60032 (35%)]\tLoss: 0.046519\n",
      "Train Epoch: 10 [21760/60032 (36%)]\tLoss: 0.031133\n",
      "Train Epoch: 10 [22400/60032 (37%)]\tLoss: 0.039632\n",
      "Train Epoch: 10 [23040/60032 (38%)]\tLoss: 0.015116\n",
      "Train Epoch: 10 [23680/60032 (39%)]\tLoss: 0.085139\n",
      "Train Epoch: 10 [24320/60032 (41%)]\tLoss: 0.095990\n",
      "Train Epoch: 10 [24960/60032 (42%)]\tLoss: 0.015795\n",
      "Train Epoch: 10 [25600/60032 (43%)]\tLoss: 0.145542\n",
      "Train Epoch: 10 [26240/60032 (44%)]\tLoss: 0.016880\n",
      "Train Epoch: 10 [26880/60032 (45%)]\tLoss: 0.057206\n",
      "Train Epoch: 10 [27520/60032 (46%)]\tLoss: 0.097690\n",
      "Train Epoch: 10 [28160/60032 (47%)]\tLoss: 0.093607\n",
      "Train Epoch: 10 [28800/60032 (48%)]\tLoss: 0.006510\n",
      "Train Epoch: 10 [29440/60032 (49%)]\tLoss: 0.019948\n",
      "Train Epoch: 10 [30080/60032 (50%)]\tLoss: 0.085537\n",
      "Train Epoch: 10 [30720/60032 (51%)]\tLoss: 0.055893\n",
      "Train Epoch: 10 [31360/60032 (52%)]\tLoss: 0.091349\n",
      "Train Epoch: 10 [32000/60032 (53%)]\tLoss: 0.054619\n",
      "Train Epoch: 10 [32640/60032 (54%)]\tLoss: 0.115272\n",
      "Train Epoch: 10 [33280/60032 (55%)]\tLoss: 0.042891\n",
      "Train Epoch: 10 [33920/60032 (57%)]\tLoss: 0.024873\n",
      "Train Epoch: 10 [34560/60032 (58%)]\tLoss: 0.141798\n",
      "Train Epoch: 10 [35200/60032 (59%)]\tLoss: 0.042646\n",
      "Train Epoch: 10 [35840/60032 (60%)]\tLoss: 0.017074\n",
      "Train Epoch: 10 [36480/60032 (61%)]\tLoss: 0.037899\n",
      "Train Epoch: 10 [37120/60032 (62%)]\tLoss: 0.091330\n",
      "Train Epoch: 10 [37760/60032 (63%)]\tLoss: 0.179807\n",
      "Train Epoch: 10 [38400/60032 (64%)]\tLoss: 0.029040\n",
      "Train Epoch: 10 [39040/60032 (65%)]\tLoss: 0.023351\n",
      "Train Epoch: 10 [39680/60032 (66%)]\tLoss: 0.024802\n",
      "Train Epoch: 10 [40320/60032 (67%)]\tLoss: 0.027715\n",
      "Train Epoch: 10 [40960/60032 (68%)]\tLoss: 0.050200\n",
      "Train Epoch: 10 [41600/60032 (69%)]\tLoss: 0.023103\n",
      "Train Epoch: 10 [42240/60032 (70%)]\tLoss: 0.092161\n",
      "Train Epoch: 10 [42880/60032 (71%)]\tLoss: 0.029214\n",
      "Train Epoch: 10 [43520/60032 (72%)]\tLoss: 0.095858\n",
      "Train Epoch: 10 [44160/60032 (74%)]\tLoss: 0.081564\n",
      "Train Epoch: 10 [44800/60032 (75%)]\tLoss: 0.036774\n",
      "Train Epoch: 10 [45440/60032 (76%)]\tLoss: 0.023816\n",
      "Train Epoch: 10 [46080/60032 (77%)]\tLoss: 0.072930\n",
      "Train Epoch: 10 [46720/60032 (78%)]\tLoss: 0.032158\n",
      "Train Epoch: 10 [47360/60032 (79%)]\tLoss: 0.056030\n",
      "Train Epoch: 10 [48000/60032 (80%)]\tLoss: 0.047271\n",
      "Train Epoch: 10 [48640/60032 (81%)]\tLoss: 0.151373\n",
      "Train Epoch: 10 [49280/60032 (82%)]\tLoss: 0.135821\n",
      "Train Epoch: 10 [49920/60032 (83%)]\tLoss: 0.223408\n",
      "Train Epoch: 10 [50560/60032 (84%)]\tLoss: 0.242661\n",
      "Train Epoch: 10 [51200/60032 (85%)]\tLoss: 0.115053\n",
      "Train Epoch: 10 [51840/60032 (86%)]\tLoss: 0.065119\n",
      "Train Epoch: 10 [52480/60032 (87%)]\tLoss: 0.104657\n",
      "Train Epoch: 10 [53120/60032 (88%)]\tLoss: 0.146975\n",
      "Train Epoch: 10 [53760/60032 (90%)]\tLoss: 0.077163\n",
      "Train Epoch: 10 [54400/60032 (91%)]\tLoss: 0.154745\n",
      "Train Epoch: 10 [55040/60032 (92%)]\tLoss: 0.026812\n",
      "Train Epoch: 10 [55680/60032 (93%)]\tLoss: 0.081251\n",
      "Train Epoch: 10 [56320/60032 (94%)]\tLoss: 0.054083\n",
      "Train Epoch: 10 [56960/60032 (95%)]\tLoss: 0.128641\n",
      "Train Epoch: 10 [57600/60032 (96%)]\tLoss: 0.005399\n",
      "Train Epoch: 10 [58240/60032 (97%)]\tLoss: 0.064880\n",
      "Train Epoch: 10 [58880/60032 (98%)]\tLoss: 0.153124\n",
      "Train Epoch: 10 [59520/60032 (99%)]\tLoss: 0.048458\n",
      "\n",
      "Test set: Average loss: 0.0811, Accuracy: 9725/10000 (97%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "optimizer = optim.SGD(model.parameters(), lr=args['lr'])\n",
    "\n",
    "for epoch in range(1, args['epochs'] + 1):\n",
    "        train(args, model, device, federated_train_loader, optimizer, epoch)\n",
    "        test(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "median-sphere",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'MNISTCNN.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accompanied-vegetarian",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "herbal-groove",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
